{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pymongo\n",
    "import os, sys\n",
    "# root_dir = \"/home/tabz/Coding/pymarl/src\"\n",
    "# sys.path = [root_dir] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.0.min.js\": \"HjagQp6T0/7bxYTAXbLotF1MLAGWmhkY5siA1Gc/pcEgvgRPtMsRn0gQtMwGKiw1\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.0.min.js\": \"ZEPPTjL+mdyqgIq+/pl9KTwzji8Kow2NnI3zWY8+sFinWP/SYJ80BnfeJsa45iYj\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.0.min.js\": \"exLqv2ACDRIaV7ZK1iL8aGzGYQvKVuT3U2CT7FsQREBxRah6JrkVCoFy0koY1YqV\"};\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.0.min.js\": \"HjagQp6T0/7bxYTAXbLotF1MLAGWmhkY5siA1Gc/pcEgvgRPtMsRn0gQtMwGKiw1\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.0.min.js\": \"ZEPPTjL+mdyqgIq+/pl9KTwzji8Kow2NnI3zWY8+sFinWP/SYJ80BnfeJsa45iYj\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.0.min.js\": \"exLqv2ACDRIaV7ZK1iL8aGzGYQvKVuT3U2CT7FsQREBxRah6JrkVCoFy0koY1YqV\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import push_notebook, show, output_notebook, export_svgs, export_png\n",
    "from bokeh.layouts import column, row, gridplot\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import Band, Span, Range1d\n",
    "from bokeh.models.sources import ColumnDataSource\n",
    "from bokeh.models.formatters import NumeralTickFormatter\n",
    "from bokeh.palettes import all_palettes, magma, Set3, Set1\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.models import FixedTicker\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from config.mongodb import REGISTRY as mongo_REGISTRY\n",
    "def get_mongo_db_client(conf_name, maxSevSelDelay=5000):    \n",
    "#     mongo_conf = mongo_REGISTRY[conf_name](None, None)\n",
    "    # Hardcode for now\n",
    "    db_url = \"mongodb://pymarlOwner:EMC7Jp98c8rE7FxxN7g82DT5spGsVr9A@gandalf.cs.ox.ac.uk:27017/pymarl\"\n",
    "    db_name = \"pymarl\"\n",
    "    client = pymongo.MongoClient(db_url, ssl=True, serverSelectionTimeoutMS=maxSevSelDelay)\n",
    "    return client, client[db_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "def get_from_sacred(path: Path):\n",
    "    data = {}\n",
    "    info_path = path / \"info.json\"\n",
    "    config_path = path / \"config.json\"\n",
    "    if not info_path.exists():\n",
    "        raise Exception('File not found')\n",
    "    with open(info_path) as info_f:\n",
    "        data[\"info\"] = json.load(info_f)\n",
    "    with open(config_path) as config_f:\n",
    "        data[\"config\"] = json.load(config_f)\n",
    "    return data\n",
    "\n",
    "def get_all_local_results(path: Path):\n",
    "    exps = defaultdict(list)\n",
    "    for exp in path.iterdir():\n",
    "        if exp.is_dir():\n",
    "            try:\n",
    "                exp_data = get_from_sacred(exp)\n",
    "                exps[exp_data[\"config\"][\"env_args\"][\"map_name\"]].append(exp_data)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    return exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoCentral():\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.conf_names = kwargs[\"conf_names\"]\n",
    "        self.db = {}\n",
    "        self._connect(self.conf_names)\n",
    "        \n",
    "    def _connect(self, conf_names):\n",
    "        self.clients = {}\n",
    "        for _name in conf_names:\n",
    "            self.clients[_name], self.db[_name] = get_mongo_db_client(_name)\n",
    "            print(\"Connected to {}\".format(_name))\n",
    "            \n",
    "    def get_exp_names(self):\n",
    "        #print(\"Loading keys...\")\n",
    "        names = []\n",
    "        for key, db in self.db.items():\n",
    "            query = db[\"runs\"].distinct(\"config.name\") # .find({\"config\":None})\n",
    "            names.extend(query)\n",
    "            print(\"Done Loading...\")\n",
    "        return names\n",
    "    \n",
    "    def get_config_and_info(self, label, keys_to_return):\n",
    "        queries = []\n",
    "        things_to_return = {\"config\"}\n",
    "        for k in keys_to_return:\n",
    "            things_to_return.add(\"info.{}\".format(k))\n",
    "        print(\"Things to return:\", things_to_return)\n",
    "        for key, db in self.db.items():\n",
    "            print(\"Retreiving info from {}\".format(key))\n",
    "            query = db.runs.find({\"config.label\": label}, things_to_return)\n",
    "            queries.extend(query)\n",
    "        return queries\n",
    "    \n",
    "    def get_config_and_info_all(self, label):\n",
    "        queries = []\n",
    "        for key, db in self.db.items():\n",
    "            print(\"Retreiving info from {}\".format(key))\n",
    "            query = db.runs.find({\"config.label\": label}, {\"config\", \"info\"})\n",
    "            queries.extend(query)\n",
    "        return queries\n",
    "    \n",
    "    def get_tag_names(self, tag, bundle=True):\n",
    "        import re\n",
    "        names = []\n",
    "        for key, db in self.db.items():            \n",
    "            query = db.runs.find({\"config.name\":{'$regex':r'^{}(.*)'.format(tag)}}, {\"config.name\":1}) # .find({\"config\":None})\n",
    "            names.extend([_q[\"config\"][\"name\"] for _q in query])\n",
    "            print(\"Done Loading...\")\n",
    "            \n",
    "        if bundle: # bundle by experiment name\n",
    "            bundle_dic = {}\n",
    "            for name in names:\n",
    "#                 print(name)\n",
    "#                 tag, exp_name_time_stamp, repeat = name.split(\"__\")\n",
    "#                 exp_name = \"_\".join(exp_name_time_stamp.split(\"_\")[:-1])\n",
    "                exp_name = name\n",
    "                if exp_name not in bundle_dic:\n",
    "                    bundle_dic[exp_name] = []\n",
    "                bundle_dic[exp_name].append(name) \n",
    "            return bundle_dic\n",
    "        return names\n",
    "\n",
    "    def get_name_prop(self, name, prop):\n",
    "        res = []\n",
    "        for key, db in self.db.items():\n",
    "            query = db.runs.find({\"config.name\":name}, {prop:1})\n",
    "            for _q in query:\n",
    "                res.append(_q)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ewma(x, alpha):\n",
    "    '''\n",
    "    Returns the exponentially weighted moving average of x.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : array-like\n",
    "    alpha : float {0 <= alpha <= 1}\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ewma : numpy array\n",
    "        the exponentially weighted moving average\n",
    "    '''\n",
    "    # coerce x to an array\n",
    "    x = np.array(x)\n",
    "    n = x.size\n",
    "    # create an initial weight matrix of (1-alpha), and a matrix of powers\n",
    "    # to raise the weights by\n",
    "    w0 = np.ones(shape=(n,n)) * (1-alpha) \n",
    "    p = np.vstack([np.arange(i,i-n,-1) for i in range(n)])\n",
    "    # create the weight matrix\n",
    "    w = np.tril(w0**p,0)\n",
    "    # calculate the ewma\n",
    "    return np.dot(w, x[::np.newaxis]) / w.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = np.array(data)\n",
    "    n = a.shape[0]\n",
    "    m, se = a.mean(axis=0), stats.sem(a, axis=0)\n",
    "    h = se * stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return m, h"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, radius=10, mode='two_sided', valid_only=False):\n",
    "    '''\n",
    "    Smooth signal y, where radius is determines the size of the window\n",
    "    mode='twosided':\n",
    "        average over the window [max(index - radius, 0), min(index + radius, len(y)-1)]\n",
    "    mode='causal':\n",
    "        average over the window [max(index - radius, 0), index]\n",
    "    valid_only: put nan in entries where the full-sized window is not available\n",
    "    '''\n",
    "    assert mode in ('two_sided', 'causal')\n",
    "    if len(y) < 2*radius+1:\n",
    "        return np.ones_like(y) * y.mean()\n",
    "    elif mode == 'two_sided':\n",
    "        convkernel = np.ones(2 * radius+1)\n",
    "        out = np.convolve(y, convkernel,mode='same') / np.convolve(np.ones_like(y), convkernel, mode='same')\n",
    "        if valid_only:\n",
    "            out[:radius] = out[-radius:] = np.nan\n",
    "    elif mode == 'causal':\n",
    "        convkernel = np.ones(radius)\n",
    "        out = np.convolve(y, convkernel,mode='full') / np.convolve(np.ones_like(y), convkernel, mode='full')\n",
    "        out = out[:-radius+1]\n",
    "        if valid_only:\n",
    "            out[:radius] = np.nan\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> 2ab8a111531d7bf21db67195b9e12016f46bb9bb
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_stats(y_key):\n",
    "    means = {}\n",
    "    stds = {}\n",
    "    nums = {}\n",
    "    for key in tqdm_notebook(keys, desc=\"params\", leave=False):\n",
    "        runs = data[key][:limit]\n",
    "#         print(runs)\n",
    "        interps = []\n",
    "\n",
    "        for run in tqdm_notebook(runs, desc=\"runs\", leave=False):\n",
    "            \n",
    "            if \"{}_T\".format(y_key) not in run:\n",
    "                print(\"Field: {} not in run for {}\".format(y_key, key))\n",
    "                continue\n",
    "            \n",
    "            xs = run[\"{}_T\".format(y_key)]\n",
    "            ys = run[y_key]\n",
    "            \n",
    "            if xs[-1] < t_needed:\n",
    "                if print_not_long_enough:\n",
    "                    print(\"Run not long enough: {} for key: {}\".format(xs[-1], key))\n",
    "                continue\n",
    "\n",
    "            # Align them\n",
    "#             diffs = len(xs) - len(ys)\n",
    "#             xs = xs[diffs:]\n",
    "            y_interp = np.interp(x_interp, xs, ys)\n",
    "\n",
    "            y_interp_smoothed = ewma(y_interp, smoother)\n",
    "#             y_interp_smoothed = y_interp\n",
    "    \n",
    "            interps.append(y_interp_smoothed)\n",
    "        \n",
    "        if interps == []:\n",
    "            continue\n",
    "\n",
    "        joined_array = np.array(interps)\n",
    "        if confidence_interval:\n",
    "            mean, std = mean_confidence_interval(joined_array, confidence=confidence_interval)\n",
    "        else:\n",
    "            mean = np.mean(joined_array, axis=0)\n",
    "            std = np.std(joined_array, axis=0)\n",
    "        means[key] = mean\n",
    "        stds[key] = std\n",
    "        nums[key] = len(interps)\n",
    "    return means, stds, nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "legend_location = \"top_left\"\n",
    "def plot(means, stds, nums, x_label, y_label, t_max, indivs=False, save_to_file=None):\n",
    "    \n",
    "    x_vals_interp = x_interp\n",
    "          \n",
    "    keys =  means.keys()\n",
    "    p = figure(plot_width=1200, plot_height=800, x_range=[0, t_max])\n",
    "    # p.output_backend = \"svg\"\n",
    "    \n",
    "    y_min = 0\n",
    "    y_max = 1\n",
    "\n",
    "    num_lines = len(keys)\n",
    "    if num_lines < 3:\n",
    "        magma_cols = [\"red\", \"green\"][:num_lines]\n",
    "    else:\n",
    "        magma_cols = Set1[num_lines]\n",
    "    colors = {}\n",
    "    for key, col in zip(keys, magma_cols):\n",
    "        colors[key] = col\n",
    "\n",
    "    for key in keys:\n",
    "\n",
    "        color = colors[key]\n",
    "        name = key\n",
    "\n",
    "        p.line(x_vals_interp, smooth(means[key]), color=color, legend=name + \" [\" + str(nums[key]) + \"]\", line_width=3)\n",
    "\n",
    "        xs = list(x_vals_interp) + list(reversed(x_vals_interp))\n",
    "\n",
    "        mm = means[key]\n",
    "        ss = stds[key]\n",
    "        ys = np.concatenate([mm - ss, np.flip(mm + ss, axis=0)])\n",
    "        lls = p.patch(xs, smooth(ys), color=color, alpha=0.2)\n",
    "\n",
    "        y_max = max(y_max, max(means[key]))\n",
    "        y_min = min(y_min, min(means[key]))\n",
    "        \n",
    "        if indivs:\n",
    "            for run in data[key][:limit]:\n",
    "                if \"{}_T\".format(y_label) not in run:\n",
    "                    continue\n",
    "\n",
    "                xs = run[\"{}_T\".format(y_label)]\n",
    "                ys = run[y_label]\n",
    "\n",
    "                p.line(xs, ys, color=color, line_width=1, alpha=0.4)\n",
    "\n",
    "                y_max = max(y_max, max(ys))\n",
    "                y_min = min(y_min, min(ys))\n",
    "        \n",
    "    p.y_range = Range1d(y_min * 1.1, y_max * 1.1)\n",
    "\n",
    "    p.grid.grid_line_width=2\n",
    "    p.grid.minor_grid_line_width=2\n",
    "    p.grid.grid_line_color=(1,1,1,0.1)\n",
    "\n",
    "    p.grid.minor_grid_line_color=(1,1,1,0.1)\n",
    "    p.xgrid.minor_grid_line_color=None\n",
    "\n",
    "    p.yaxis.formatter = NumeralTickFormatter(format=\"0.0a\")\n",
    "    p.yaxis[0].ticker.desired_num_ticks = 5\n",
    "    p.yaxis[0].ticker.num_minor_ticks = 2\n",
    "\n",
    "    p.xaxis.formatter = NumeralTickFormatter(format=\"0.0a\")\n",
    "\n",
    "    p.legend.location = (0,0)\n",
    "\n",
    "    p.xaxis.axis_label= x_label\n",
    "    p.yaxis.axis_label= y_label\n",
    "\n",
    "#     p.xaxis.axis_label_standoff=-20\n",
    "#     p.yaxis.axis_label_standoff=-30\n",
    "\n",
    "    p.xaxis.axis_label_text_font_style=\"normal\"\n",
    "    p.yaxis.axis_label_text_font_style=\"normal\"\n",
    "\n",
    "    p.xaxis.axis_label_text_font_size=\"24pt\"\n",
    "    p.yaxis.axis_label_text_font_size=\"24pt\"\n",
    "\n",
    "    p.xaxis.major_label_text_font_size=\"24pt\"\n",
    "    p.yaxis.major_label_text_font_size=\"24pt\"\n",
    "\n",
    "    p.legend.label_text_font_size=\"15pt\"\n",
    "    p.legend.visible=True\n",
    "    p.legend.location=legend_location\n",
    "    p.legend.background_fill_alpha = 0.4\n",
    "#     p.legend.orientation=\"horizontal\"\n",
    "#     p.legend.glyph_width=60\n",
    "#     p.legend.glyph_height=100\n",
    "\n",
    "    p.title.text_font_size=\"24pt\"\n",
    "\n",
    "#     p.h_symmetry = False\n",
    "    p.min_border_right = 70\n",
    "    p.min_border_left = 0\n",
    "    p.min_border_bottom = 0\n",
    "#     p.yaxis.axis_label_text_line_height = 1\n",
    "#     p.yaxis.bounds = (400,400)\n",
    "#     p.yaxis.bounds\n",
    "#     p.yaxis.axis_label_text_baseline=\"top\"\n",
    "#     p.yaxis.axis_label_text_align=\"center\"\n",
    "    p.min_border_top = 30\n",
    "#     p.border_fill_color = (1,1,1,0.1)\n",
    "\n",
    "    p.axis.axis_line_width = 3\n",
    "    p.axis.major_tick_line_width = 5\n",
    "    p.axis.major_tick_in = 10\n",
    "    p.axis.major_tick_out = 5\n",
    "\n",
    "    if save_to_file is not None:\n",
    "        export_png(p, filename=save_to_file)\n",
    "    # show(p, notebook_handle=True)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 251,
=======
   "execution_count": 13,
>>>>>>> 2ab8a111531d7bf21db67195b9e12016f46bb9bb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to gandalf_pymarl\n"
     ]
    }
   ],
   "source": [
    "mongo_central = MongoCentral(conf_names=[\"gandalf_pymarl\"])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 252,
=======
   "execution_count": 14,
>>>>>>> 2ab8a111531d7bf21db67195b9e12016f46bb9bb
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label = \"ppo_pred_prey_test_mingfei\" \n",
    "# label = \"ppo_stag_hunt_test_mingfei\" \n",
    "# label = \"ppo_sc2_corridor_mingfei\" # done\n",
    "# label = \"ppo_sc2_6h_vs_8z_mingfentii\" # done\n",
    "# label = \"ppo_sc2_2s3z_mingfei\" # done\n",
    "# label = \"ppo_sc2_bane_vs_bane_mingfei\" # done\n",
    "# label = \"ppo_sc2_3m_mingfei\" # done\n",
    "# label = \"ppo_sc2_2s_vs_1sc_mingfei\"\n",
    "# label = \"ppo_sc2_2m_vs_1z_mingfei\" # done\n",
    "\n",
    "# experiments start on 29 Dec, 2020\n",
    "# label = \"sc2_3m_new_mingfei\" # running 4 seeds; ablations: GAE vs TD_Error, 64 vs 256; rnn vs cnn\n",
    "# label = \"ppo_sc2_3s5z_new_mingfei\" # running 4 seeds; ablations: GAE vs TD_Error, 64 vs 256, rnn vs cnn\n",
    "# label = \"sc2_2m_vs_1z_new_mingfei\" # running 4 seeds; ablations: 64 vs 256 (done)\n",
    "# label = \"sc2_3s5z_vs_3s6z_new_mingfei\" # running 4 seeds; ablations: 64 vs 256, rnn vs cnn\n",
    "# label = \"sc2_6h_vs_8z_new_mingfei\" # running 4 seeds; ablations: 64 vs 256, rnn vs cnn\n",
    "# label = \"sc2_corridor_new_mingfei\" # running 4 seeds; ablations: 64 vs 256, rnn vs cnn\n",
    "# label = \"sc2_1c3s5z_new_mingfei\" # running 4 seeds; (done)\n",
    "# label = \"sc2_3s_vs_5z_new_mingfei\" # running 4 seeds; baselines: qmix, iql; ablations: rnn vs cnn\n",
    "# label = \"sc2_MMM2_new_mingfei\" # running 4 seeds; baselines: qmix, iql; ablations: 64 vs 256 \n",
    "# label = \"sc2_2s3z_new_mingfei\" # running 4 seeds (done)\n",
    "# label = \"sc2_bane_vs_bane_new_mingfei\" # running 4 seeds (done)\n",
    "# label = \"sc2_2c_vs_64zg_new_mingfei\" # running 4 seeds; ablations: 64 vs 256 (done) \n",
    "\n",
    "# experiments start on 5 Apr, 2021\n",
<<<<<<< HEAD
    "# label = \"ppo_sc2_1c3s5z_mingfei\" # same; done\n",
    "# label = \"ppo_sc2_2c_vs_64zg_mingfei\" # boosted; done\n",
    "# label = \"ppo_sc2_2s_vs_1sc_mingfei\" # same; done\n",
    "# label = \"ppo_sc2_2s3z_mingfei\" # same; done\n",
    "# label = \"ppo_sc2_3s_vs_5z_mingfei\" # weird; done\n",
    "# label = \"ppo_sc2_3s5z_mingfei\" # weird; done\n",
    "# label = \"sc2_3s5z_vs_3s6z_mingfei\" # done\n",
    "# label = \"sc2_5m_vs_6m_mingfei\" # done\n",
    "# label = \"sc2_6h_vs_8z_mingfei\" # done\n",
    "# label = \"sc2_10m_vs_11m_mingfei\" # done\n",
    "# label = \"sc2_27m_vs_30m_mingfei\" # done\n",
    "# label = \"sc2_bane_vs_bane_mingfei\" # done\n",
    "# label = \"sc2_corridor_mingfei\" # done\n",
    "# label = \"sc2_MMM2_mingfei\" \n",
    "\n",
    "# Bozhidar results\n",
    "# label = []\n",
    "# label += [\"3jan_ppo_gae\"] # - PPO with CentralV critic\n",
    "# label += [\"15feb_comappo_bs8\"] # - PPO with COMA critic and baseline\n",
    "# label += [\"16feb_comappovdn_bs8\"] # - PPO with VDN factored COMA critic and baseline\n",
    "# label += [\"ppo_sc2_1c3s5z_mingfei\", \"ppo_sc2_2c_vs_64zg_mingfei\", \"ppo_sc2_2s_vs_1sc_mingfei\", \"ppo_sc2_2s3z_mingfei\", \"ppo_sc2_3s_vs_5z_mingfei\"]\n",
    "# label += [\"ppo_sc2_3s5z_mingfei\", \"sc2_3s5z_vs_3s6z_mingfei\", \"sc2_5m_vs_6m_mingfei\", \"sc2_6h_vs_8z_mingfei\", \"sc2_10m_vs_11m_mingfei\"]\n",
    "# label += [\"sc2_27m_vs_30m_mingfei\", \"sc2_bane_vs_bane_mingfei\", \"sc2_corridor_mingfei\", \"sc2_MMM2_mingfei\"]\n",
    "# label += [\"qmix_20dec20\"] #  contains some hard/superhard maps for 10mil steps\n",
    "# label += [\"qmix__03_October_2020_SC2_410\"] # only 2mil\n",
    "\n",
    "# Results 0418\n",
    "label = []\n",
    "label += [\"3jan_ppo_gae\"] # - PPO with CentralV critic\n",
    "label += [\"15feb_comappo_bs8\"] # - PPO with COMA critic and baseline\n",
    "label += [\"16feb_comappovdn_bs8\"] # - PPO with VDN factored COMA critic and baseline\n",
    "label += [\"qmix_20dec20\"] #  contains some hard/superhard maps for 10mil steps\n",
    "label += [\"qmix__03_October_2020_SC2_410\"] # only 2mil\n",
    "\n",
    "label += [\"ppo_sc2_1c3s5z_0418\", \"ppo_sc2_2c_vs_64zg_0418\", \"ppo_sc2_2s_vs_1sc_0418\", \"ppo_sc2_2s3z_0418\", \n",
    "          \"ppo_sc2_3s_vs_5z_0418\", \"ppo_sc2_3s5z_0418\", \"ppo_sc2_3s5z_vs_3s6z_0418\", \"ppo_sc2_5m_vs_6m_0418\", \n",
    "          \"ppo_sc2_6h_vs_8z_0418\", \"ppo_sc2_10m_vs_11m_0418\", \"ppo_sc2_27m_vs_30m_0418\",\n",
    "          \"ppo_sc2_bane_vs_bane_0418\", \"ppo_sc2_corridor_0418\", \"ppo_sc2_MMM2_0418\"]"
=======
    "# label = \"ppo_sc2_1c3s5z_mingfei\"\n",
    "label = \"ppo_sc2_2c_vs_64zg_mingfei\"\n",
    "# label = \"ppo_sc2_2s_vs_1sc_mingfei\"\n",
    "# label = \"ppo_sc2_2s3z_mingfei\"\n",
    "# label = \"ppo_sc2_3s_vs_5z_mingfei\"\n",
    "# label = \"ppo_sc2_3s5z_mingfei\"\n",
    "# label = \"sc2_3s5z_vs_3s6z_mingfei\"\n",
    "# label = \"sc2_5m_vs_6m_mingfei\" \n",
    "# label = \"sc2_6h_vs_8z_mingfei\" \n",
    "# label = \"sc2_10m_vs_11m_mingfei\"\n",
    "# label = \"sc2_27m_vs_30m_mingfei\"\n",
    "# label = \"sc2_bane_vs_bane_mingfei\"\n",
    "# label = \"sc2_corridor_mingfei\" \n",
    "# label = \"sc2_MMM2_mingfei\" \n",
    "# label = \"sc2_3s_vs_5z_new_mingfei\" # running 4 seeds; baselines: qmix, iql (done)\n",
    "# label = \"sc2_MMM2_new_mingfei\" # running 4 seeds; baselines: qmix, iql; ablations: 64 vs 256 (done)\n",
    "# label = \"sc2_2s3z_new_mingfei\" # running 4 seeds\n",
    "label = \"sc2_1c3s5z_iac\" # running 4 seeds\n",
    "path = Path('/Users/benellis/src/pymarl-dev/results/sacred')\n"
>>>>>>> 2ab8a111531d7bf21db67195b9e12016f46bb9bb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 253,
=======
   "execution_count": 17,
>>>>>>> 2ab8a111531d7bf21db67195b9e12016f46bb9bb
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Retreiving info from gandalf_pymarl\n",
      "Number of experiments:  341\n"
     ]
    }
   ],
   "source": [
    "all_exps = []\n",
    "for la in label:\n",
    "    all_exps += mongo_central.get_config_and_info_all(la)\n",
    "print('Number of experiments: ', len(all_exps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
=======
      "Number of experiments:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
>>>>>>> 2ab8a111531d7bf21db67195b9e12016f46bb9bb
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# maps: 1c3s5z, 2c_vs_64zg, 2s_vs_1sc, 2s3z, 3s_vs_5z, 3s5z, \n",
    "# 3s5z_vs_3s6z, 5m_vs_6m, 6h_vs_8z, 10m_vs_11m, 27m_vs_30m, bane_vs_bane, corridor, MMM2\n",
    "selected_map = \"MMM2\"\n",
    "if selected_map in [\"2s_vs_1sc\", \"3s_vs_5z\", \"bane_vs_bane\"]:\n",
    "    legend_location = \"bottom_right\"\n",
    "else:\n",
    "    legend_location = \"top_left\"\n",
    "exps = []\n",
    "for e in all_exps:\n",
    "    if e['config']['env_args']['map_name'] == selected_map:\n",
    "        exps.append(e)\n",
    "print(len(exps))"
=======
    "exps = get_all_local_results(path)\n",
    "print('Number of experiments: ', len(exps.keys()))\n"
>>>>>>> 2ab8a111531d7bf21db67195b9e12016f46bb9bb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 287,
=======
   "execution_count": null,
>>>>>>> 2ab8a111531d7bf21db67195b9e12016f46bb9bb
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Keys in info:\n",
      "['advantage_mean',\n",
      " 'agent_grad_norm',\n",
      " 'agent_loss',\n",
      " 'battle_won_mean',\n",
      " 'critic_grad_norm',\n",
      " 'critic_loss',\n",
      " 'dead_allies_mean',\n",
      " 'dead_enemies_mean',\n",
      " 'ep_length_mean',\n",
      " 'episode',\n",
      " 'epsilon',\n",
      " 'grad_norm',\n",
      " 'loss',\n",
      " 'loss_pi',\n",
      " 'policy_entropy',\n",
      " 'q_taken_mean',\n",
      " 'return_mean',\n",
      " 'return_std',\n",
      " 'target_mean',\n",
      " 'td_error_abs',\n",
      " 'test_battle_won_mean',\n",
      " 'test_dead_allies_mean',\n",
      " 'test_dead_enemies_mean',\n",
      " 'test_ep_length_mean',\n",
      " 'test_return_mean',\n",
      " 'test_return_std']\n"
=======
      "> \u001b[0;32m<ipython-input-18-9ef164f37271>\u001b[0m(5)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      3 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m    \u001b[0mexp_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"info\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexp_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m        \u001b[0minfo_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> type(exp)\n",
      "<class 'str'>\n",
      "ipdb> type(exps)\n",
      "<class 'collections.defaultdict'>\n"
>>>>>>> 2ab8a111531d7bf21db67195b9e12016f46bb9bb
     ]
    }
   ],
   "source": [
    "# Keys\n",
    "info_keys = set()\n",
    "for exp in exps:\n",
    "    import pdb; pdb.set_trace()\n",
    "    exp_keys = exp[\"info\"].keys()\n",
    "    for key in exp_keys:\n",
    "        info_keys.add(key)\n",
    "print(\"Keys in info:\")\n",
    "pprint.pprint(list(filter(lambda x: not x.endswith(\"_T\"), sorted(info_keys))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = [\"name\"]\n",
    "\n",
    "if selected_map in [\"3s_vs_5z\", \"3s5z_vs_3s6z\", \"5m_vs_6m\", \"6h_vs_8z\", \"10m_vs_11m\", \"27m_vs_30m\", \"corridor\", \"MMM2\"]:\n",
    "    t_max = 10000 * 1000\n",
    "else:\n",
    "    t_max = 2000 * 1000\n",
    "t_needed = 100 * 1000\n",
    "\n",
    "limit = 50\n",
    "x_key = \"T env\" # x-axis label\n",
    "x_interp = np.linspace(0, t_max, 2001)\n",
    "\n",
    "confidence_interval = False\n",
    "smoother = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys.remove('name-ppo_cnn')\n",
    "# keys.remove('name-ppo_central_v')\n",
    "# keys.remove('name-ppo_pred_prey')\n",
    "# keys.remove('name-ppo_new')\n",
    "# keys.remove('name-ppo')\n",
    "# keys.remove('name-ppo_rnn2')\n",
    "# keys.remove('name-ppo_cv_big')\n",
    "# keys.remove('name-ppo_cv')\n",
    "# keys.remove('name-ppo_correct')\n",
    "key_mapping = {\"name-3jan_ppo_gae\": \"DecClip_CentralV\", \"name-central_ppo_rnn\": \"CenClip_CentralV\",\n",
    "               \"name-central_ppo_rnn_masked\": \"CenClip_CentralV\", \"name-16feb_comappovdn_bs8\": \"DecClip_COMA-VDN\", \n",
    "               \"name-15feb_comappo_bs8\": \"DecClip_COMA\", \"name-qmix_sc2_410\": \"QMIX\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name-3jan_ppo_gae\n",
      "name-3jan_ppo_gae\n",
      "name-3jan_ppo_gae\n",
      "name-3jan_ppo_gae\n",
      "name-15feb_comappo_bs8\n",
      "name-15feb_comappo_bs8\n",
      "name-15feb_comappo_bs8\n",
      "name-15feb_comappo_bs8\n",
      "name-16feb_comappovdn_bs8\n",
      "name-16feb_comappovdn_bs8\n",
      "name-16feb_comappovdn_bs8\n",
      "name-16feb_comappovdn_bs8\n",
      "name-qmix_sc2_410\n",
      "name-qmix_sc2_410\n",
      "name-qmix_sc2_410\n",
      "name-qmix_sc2_410\n",
      "name-qmix_sc2_410\n",
      "name-qmix_sc2_410\n",
      "name-qmix_sc2_410\n",
      "name-qmix_sc2_410\n",
      "Keys:  ['DecClip_COMA', 'DecClip_COMA-VDN', 'DecClip_CentralV', 'QMIX']\n"
     ]
    }
   ],
   "source": [
    "keys = set()\n",
    "data = {}\n",
    "for exp in exps:\n",
    "#     print(exp)\n",
    "    exp_config = exp[\"config\"]\n",
    "    if exp[\"info\"] == {}:\n",
    "        continue\n",
    "    exp_info = exp[\"info\"]\n",
    "    params_str = \"__\".join([\"{}-{}\".format(param, exp_config[param]) for param in params])\n",
    "    print(params_str)\n",
    "    if params_str not in key_mapping:\n",
    "        continue\n",
    "    else: \n",
    "        params_str = key_mapping[params_str]\n",
    "    keys.add(params_str)\n",
    "    if params_str not in data:\n",
    "        data[params_str] = [exp_info]\n",
    "    else:\n",
    "        data[params_str].append(exp_info)\n",
    "\n",
    "keys = sorted(keys)\n",
    "print(\"Keys: \", keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_not_long_enough = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# keys_to_plot = [\"battle_won_mean\", \"return_mean\", \"test_battle_won_mean\", \"test_return_mean\", \"critic_loss\", \"dead_allies_mean\", \"dead_enemies_mean\", \"entropy\"]\n",
    "keys_to_plot = [\"test_battle_won_mean\"]\n",
    "# keys_to_plot = [\"rewards\", \"approx_KL\", \"entropy\", \"critic_loss\", \"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255b03a089654a149d58be093e524ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='keys', max=1, style=ProgressStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0cb4cee6334fea8ea5e10698c61a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='params', max=4, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1077e821b0c44ce8bca7e66a639675a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='runs', max=4, style=ProgressStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80d6be672e4474cbffd15dffde16169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='runs', max=4, style=ProgressStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e5851f1f0c428fade5dec475b7d392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='runs', max=4, style=ProgressStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e416547637e44f9ea80c8f4682d321fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='runs', max=8, style=ProgressStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "folder_path = \"/Users/mingfeisun/Documents/Oxford/Research/2020/projects/PPO/plots_0419\"\n",
    "for y_key in tqdm_notebook(keys_to_plot, desc=\"keys\", leave=False):\n",
    "    x_key = \"Timesteps (map: %s)\"%(selected_map)\n",
    "    m, s, n = get_stats(y_key)\n",
    "    plot(m, s, n, x_key, y_key, t_max, indivs=False, save_to_file='%s/map-%s_%s.png'%(folder_path, selected_map, y_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymarl-dev",
   "language": "python",
   "name": "pymarl-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
