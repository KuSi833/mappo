action_selector: multinomial
agent_model: flounderl_recursive
agent_output_type: policies
agent_share_params: True
agent_level1_share_params: True
agent_level2_share_params: True
agent_level3_share_params: True
critic_share_params: True
lr_agent: 5e-4
lr_critic: 5e-4
flounderl_agent_model: flounderl_agent
flounderl_agent_model_level1: flounderl_recurrent_agent_level1
flounderl_agent_model_level2: flounderl_recurrent_agent_level2
flounderl_agent_model_level3: flounderl_recurrent_agent_level3
flounderl_agent_use_past_actions: True
flounderl_critic: flounderl_critic
flounderl_critic_use_past_actions: True
flounderl_critic_use_sampling: False
flounderl_critic_sample_size: 1000
flounderl_epsilon_start: 0.5
flounderl_epsilon_finish: 0.05
flounderl_epsilon_time_length: 20000
flounderl_epsilon_decay_mode: "exp"
flounderl_exploration_mode: "softmax"
flounderl_exploration_mode_level1: ~
flounderl_exploration_mode_level2: ~
flounderl_exploration_mode_level3: ~
flounderl_use_entropy_regularizer: False
flounderl_use_obs_intersections: True
flounderl_entropy_loss_regularization_factor: 0.000005
gamma: 0.99
learner: flounderl
multiagent_controller: flounderl_mac
n_critic_learner_reps: 4
n_pair_samples: ~
obs_last_action: True
runner: flounderl
T_target_critic_update_interval: 661500
td_lambda: 0.8
use_replay_buffer: False
mackrel_logit_bias: 1.5
use_batch_norm: True
use_full_observability: False


