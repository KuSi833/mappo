action_selector: multinomial
agent_output_type: policies
coma_critic_use_sampling: True
coma_epsilon_start: 0.5
coma_epsilon_finish: 0.05
coma_epsilon_time_length: 20000
coma_epsilon_decay_mode: "exp"
coma_exploration_mode: "softmax"
coma_use_entropy_regularizer: False
coma_entropy_loss_regularization_factor: 0.000005
gamma: 0.99
learner: coma_joint
lr_agent: 5e-4
lr_critic: 5e-4
n_critic_learner_reps: 54
obs_last_action: True
target_critic_update_interval: 661500
td_lambda: 0.8
use_replay_buffer: False
multiagent_controller: coma_joint_mac
coma_joint_lambda_size: 32
coma_joint_epsilon_start: 1.0
coma_joint_epsilon_finish: 0.05
coma_joint_epsilon_time_length: 100000
coma_joint_epsilon_size: 32
coma_joint_use_epsilon_seed: True
coma_joint_random_seed_max: 10000000000
coma_joint_multiagent_network: coma_joint_non-recurrent_multiagent_nn
coma_joint_noise_hidden_layer_size: 64
runner: coma_joint
