action_selector: multinomial
agent: coma_recursive_ac
agent_model: coma_recursive
agent_output_type: policies
agents_encoder_size: 64
agents_hidden_state_size: 64
batch_size: 32
batch_size_run: 32
coma_critic_sample_size: 800
coma_critic_use_sampling: True
coma_entropy_loss_regularization_factor: 5e-06
coma_epsilon_decay_mode: linear
coma_epsilon_finish: 0.05
coma_epsilon_start: 0.5
coma_epsilon_time_length: 10000
coma_exploration_mode: softmax
coma_use_entropy_regularizer: False
debug_mode: None
debug_verbose: False
env: sc1
env_stats_aggregator: sc1
env_args:
  map_name: m5v5_c_far
  hostname: localhost
  step_mul: 7
  episode_limit: 70
gamma: 0.99
learner: coma
lr_agent: 0.0005
lr_critic: 0.005
mongodb_profile: gandalf_pymarl
multiagent_controller: coma_mac
n_critic_learner_reps: 4
n_loops_per_thread_or_sub_or_main_process: 0
n_subprocesses: 0
n_threads_per_subprocess_or_main_process: 0
obs_last_action: True
observe: True
observe_db: True
run_mode: sequential
runner: coma
runner_test_batch_size: 32
save_model: False
save_model_interval: 10e6
share_agent_params: True
t_max: 5000000
target_critic_update_interval: 66150
td_lambda: 0.8
tensorboard: False
test_interval: 2000
test_nepisode: 30
use_cuda: True
use_replay_buffer: False
use_tensorboard: False


#defaults: default coma sc1
#batch_size: 32
#coma_critic_use_sampling: True
#coma_critic_sample_size: 1620
#coma_epsilon_start: 0.5
#coma_epsilon_finish: 0.05
#coma_epsilon_time_length: 750000
#coma_epsilon_decay_mode: "exp"
#coma_exploration_mode: "softmax"
#coma_use_entropy_regularizer: False
#env_args:
#  map_name: m5v5_c_far
#  hostname: localhost
#  step_mul: 7
#  episode_limit: 70
#env_stats_aggregator: sc1
#n_critic_learner_reps: 4
#n_loops_per_thread_or_sub_or_main_process: 1
#n_subprocesses: 32
#target_critic_update_interval: 66150
