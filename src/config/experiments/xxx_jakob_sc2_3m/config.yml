action_selector: multinomial
agent_level1_share_params: True
agent_level2_share_params: True
agent_level3_share_params: True
critic_level1_share_params: True
critic_level2_share_params: True
critic_level3_share_params: True
agents_encoder_size: 64
agents_hidden_state_size: 64
batch_size: 32
batch_size_run: 32
coma_critic_sample_size: 800
coma_critic_use_sampling: True
coma_entropy_loss_regularization_factor: 5e-06
coma_epsilon_decay_mode: linear
coma_epsilon_finish: 0.01
coma_epsilon_start: 0.5
coma_epsilon_time_length: 50000
coma_exploration_mode: softmax
coma_use_entropy_regularizer: False
debug_mode: None
debug_verbose: False
env: sc2
env_stats_aggregator: sc2
env_args:
  difficulty: "3"
  episode_limit: 40
  heuristic_function: False
  measure_fps: True
  move_amount: 5
  reward_death_value: 10
  reward_negative_scale: 0.5
  reward_only_positive: True
  reward_scale: False
  reward_scale_rate: 0
  reward_win: 200
  state_last_action: True
  step_mul: 8
  map_name: 3m_3m
  intersection_global_view: False
gamma: 0.99
learner: xxx
lr_agent_level1: 0.0005
lr_critic_level1: 0.005
lr_agent_level2: 0.0005
lr_critic_level2: 0.005
lr_agent_level3: 0.0005
lr_critic_level3: 0.005
mongodb_profile: gandalf_pymarl
multiagent_controller: xxx_mac
n_critic_level1_learner_reps: 4
n_critic_level2_learner_reps: 4
n_critic_level3_learner_reps: 4
n_loops_per_thread_or_sub_or_main_process: 0
n_pair_samples: ~
n_subprocesses: 0
n_threads_per_subprocess_or_main_process: 0
obs_last_action: True
observe: True
observe_db: True
run_mode: sequential
runner: xxx
runner_test_batch_size: 32
save_model: False
save_model_interval: 10e6
share_agent_params: True
t_max: 5000000
T_target_critic_level1_update_interval: 66150
T_target_critic_level2_update_interval: 66150
T_target_critic_level3_update_interval: 66150
td_lambda: 0.8
tensorboard: False
test_interval: 2000
test_nepisode: 30
use_cuda: True
use_replay_buffer: False
use_tensorboard: Fals
xxx_agent_model_level1: xxx_recurrent_agent_level1
xxx_agent_model_level2: xxx_recurrent_agent_level2
xxx_agent_model_level3: xxx_recurrent_agent_level3
xxx_agent_level1_use_past_actions: True
xxx_agent_level2_use_past_actions: True
xxx_agent_level3_use_past_actions: True
xxx_agent_level3_use_past_actions_level1: True
xxx_critic_level1: xxx_critic_level1
xxx_critic_level2: xxx_critic_level2
xxx_critic_level3: xxx_critic_level3
xxx_critic_level1_sample_size: 1620
xxx_critic_level2_sample_size: 1620
xxx_critic_level3_sample_size: 1620
xxx_critic_level1_use_past_actions: True
xxx_critic_level2_use_past_actions: True
xxx_critic_level3_use_past_actions: True
xxx_critic_level2_use_past_actions_level1: True
xxx_critic_level1_use_sampling: True
xxx_critic_level2_use_sampling: True
xxx_critic_level3_use_sampling: True
xxx_epsilon_start_level1: 0.5
xxx_epsilon_finish_level1: 0.05
xxx_epsilon_time_length_level1: 50000
xxx_epsilon_start_level2: 0.5
xxx_epsilon_finish_level2: 0.05
xxx_epsilon_time_length_level2: 50000
xxx_epsilon_start_level3: 0.5
xxx_epsilon_finish_level3: 0.05
xxx_epsilon_time_length_level3: 50000
xxx_epsilon_decay_mode_level1: linear
xxx_epsilon_decay_mode_level2: linear
xxx_epsilon_decay_mode_level3: linear
xxx_exploration_mode_level1: softmax
xxx_exploration_mode_level2: softmax
xxx_exploration_mode_level3: softmax
xxx_delegation_probability_bias: 0.5
xxx_use_obs_intersections: True
xxx_use_entropy_regularizer: False
xxx_agent_level3_use_past_actions_level2: True
defaults: xxx